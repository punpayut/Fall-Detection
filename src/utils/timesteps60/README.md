# Fall Detection Utility Scripts

This directory contains Python scripts for processing video data to extract human pose keypoints, create sequences from these keypoints, display them, and split the dataset for model training in a fall detection project.

## Scripts Overview

### 1. `common_keypoints.py`
   - **Purpose**: Defines shared constants and configurations for human body keypoints.
   - **Key Features**:
     - `COCO_KEYPOINT_NAMES_BASE`: A base list of 17 keypoint names in COCO order (e.g., "Nose", "Left Eye", "Right Shoulder").
     - `NUM_KEYPOINTS`: The total number of keypoints (17).
     - `KEYPOINT_ORDER_COCO`: Keypoints in the standard COCO order.
     - `KEYPOINT_ORDER_ALPHABETICAL`: Keypoints sorted alphabetically, used for structuring data in `.npy` files.
     - `SKELETON_CONNECTIONS_NAMED`: Defines the connections between keypoints to form a human skeleton, using human-readable names.
     - `SKELETON_CONNECTIONS_INDEXED`: Converts named connections to index-based connections (based on `KEYPOINT_ORDER_COCO`) for plotting.
   - **Usage**: This script is imported by other scripts (`create_seq.py`, `display_seq.py`) to ensure consistency in keypoint definitions and skeleton structure.

### 2. `extract_keypoint.py`
   - **Purpose**: Extracts 17 human pose keypoints from video files and saves them into CSV files.
   - **Key Features**:
     - Uses `mediapipe.solutions.pose` for pose estimation.
     - Processes videos (e.g., `.mp4`, `.avi`, `.mov`) from specified input directories (`Fall/Raw_Video/`, `No_Fall/Raw_Video/`).
     - For each frame in a video, it extracts X, Y coordinates and a confidence score for each of the 17 defined keypoints.
     - Outputs a CSV file for each video (e.g., `video_name_keypoints.csv`) in a corresponding `Keypoints_CSV` directory (e.g., `Fall/Keypoints_CSV/`).
     - CSV format: `Frame, Keypoint, X, Y, Confidence`.
   - **Dependencies**: `opencv-python`, `mediapipe`.
   - **To Run**: `python extract_keypoint.py` (Ensure the dataset directory structure is set up as expected by the script, typically with `Fall` and `No_Fall` subdirectories containing `Raw_Video` folders).

### 3. `create_seq.py`
   - **Purpose**: Processes the keypoint data from CSV files (generated by `extract_keypoint.py`) into fixed-length sequences, performs interpolation and padding, and saves them as `.npy` files. It also generates a JSON file listing all created sequences and their labels.
   - **Key Features**:
     - Reads keypoint data from CSV files located in `INPUT_ROOT_DIR/{Fall|No_Fall}/Keypoints_CSV/`.
     - Pivots CSV data to have features per frame.
     - **Keypoint Ordering**: Ensures keypoint data in the output `.npy` files is structured according to `KEYPOINT_ORDER_ALPHABETICAL` from `common_keypoints.py`.
     - **Interpolation**: Linearly interpolates missing X and Y coordinates within a video.
     - **Padding**: If a video has fewer frames than `SEQUENCE_LENGTH`, it pads the sequence by repeating the last valid frame's data.
     - **Sequencing**: For videos longer than `SEQUENCE_LENGTH`, it creates multiple overlapping sequences using a sliding window approach with `STEP_SIZE_FALL` or `STEP_SIZE_NO_FALL`.
     - Outputs `.npy` files (each containing one sequence of shape `(SEQUENCE_LENGTH, NUM_KEYPOINTS * 3)`) into `OUTPUT_ROOT_DIR/_temp_npy_sequences/{Fall|No_Fall}/`.
     - Generates a JSON file (e.g., `sequences_info_padded_interpolated_{process_type}_{timestamp}.json`) in `OUTPUT_ROOT_DIR` that lists paths to all generated `.npy` files and their corresponding labels (0 for No_Fall, 1 for Fall).
   - **Configuration**: `SEQUENCE_LENGTH`, `STEP_SIZE_FALL`, `STEP_SIZE_NO_FALL`, `INPUT_ROOT_DIR`, `OUTPUT_ROOT_DIR` can be configured within the script.
   - **Dependencies**: `numpy`, `pandas`, `common_keypoints.py`.
   - **To Run**: `python create_seq.py --process_type [fall|no_fall|both]` (e.g., `python create_seq.py --process_type both`).

### 4. `display_seq.py`
   - **Purpose**: Loads a single `.npy` sequence file (generated by `create_seq.py`), visualizes the skeleton animation, and saves the animation as a GIF.
   - **Key Features**:
     - Takes a path to a `.npy` file as a command-line argument.
     - **Remapping**: Loads sequence data (assumed to be in `KEYPOINT_ORDER_ALPHABETICAL`) and remaps it to `KEYPOINT_ORDER_COCO` for consistent plotting using definitions from `common_keypoints.py`.
     - Uses `matplotlib.animation` to create the animation.
     - Draws keypoints and connects them based on `SKELETON_CONNECTIONS_INDEXED` from `common_keypoints.py`.
     - Saves the animation as a `.gif` file in the same directory as the input `.npy` file.
   - **Dependencies**: `numpy`, `matplotlib`, `common_keypoints.py`.
   - **To Run**: `python display_seq.py path/to/your_sequence.npy`

### 5. `display_skeleton.py`
   - **Purpose**: Reads keypoint data directly from a CSV file (as generated by `extract_keypoint.py`), visualizes the skeleton animation, and saves it as a GIF.
   - **Key Features**:
     - Reads frame-by-frame keypoint data from a specified CSV file.
     - Uses a predefined COCO-compatible keypoint order and skeleton structure internally for plotting.
     - Creates an animation of the skeleton.
     - Saves the animation as `skeleton_animation.gif` in the script's directory.
     - If the specified CSV is not found, it can create and use a dummy CSV for demonstration.
   - **Dependencies**: `matplotlib`, `numpy`.
   - **To Run**: Modify the `csv_file_path` variable in the `if __name__ == "__main__":` block to point to your CSV file, then run `python display_skeleton.py`.

### 6. `split_dataset_v2.py`
   - **Purpose**: Splits the dataset of `.npy` sequences (prepared by `create_seq.py`) into training, validation, and test sets. It organizes these files into a new directory structure.
   - **Key Features**:
     - Reads the list of sequences and their labels from the JSON file generated by `create_seq.py` (e.g., `sequences_info_padded_interpolated_both_*.json`).
     - Splits the data based on `SPLIT_RATIOS` (e.g., 70% train, 15% val, 15% test), attempting a stratified split if multiple classes are present.
     - Copies the `.npy` files from the temporary location (e.g., `Model_Ready_Dataset_Padded_Interpolated/_temp_npy_sequences/`) into the `FINAL_SPLIT_OUTPUT_ROOT` directory, structured as:
       ```
       Final_Dataset_Splits/
       ├── train/
       │   ├── fall/
       │   │   └── sequence1.npy
       │   └── no_fall/
       │       └── sequence2.npy
       ├── val/
       │   └── ...
       └── test/
           └── ...
       ```
     - Generates a `dataset_summary.csv` file in `FINAL_SPLIT_OUTPUT_ROOT` detailing the final location, label, and split for each sequence.
   - **Configuration**: `PROCESSED_DATA_ROOT`, `FINAL_SPLIT_OUTPUT_ROOT`, `SPLIT_RATIOS` can be configured.
   - **Dependencies**: `numpy`, `pandas`, `scikit-learn`.
   - **To Run**: `python split_dataset_v2.py --process_type_for_json [fall|no_fall|both]` (This refers to which JSON info file to use, typically 'both').

## General Workflow

1. **Collect Videos**: Place raw videos into `Fall/Raw_Video/` and `No_Fall/Raw_Video/` directories (or as configured in `extract_keypoint.py`).
2. **Extract Keypoints**: Run `extract_keypoint.py` to generate CSV files containing keypoint data for each video.
3. **Create Sequences**: Run `create_seq.py` to process these CSVs into `.npy` sequence files and a master JSON list.
4. **(Optional) Display Sequences/Skeletons**:
   - Use `display_seq.py` to view an animation of a specific `.npy` sequence.
   - Use `display_skeleton.py` to view an animation directly from a keypoint CSV file.
5. **Split Dataset**: Run `split_dataset_v2.py` to organize the `.npy` sequences into `train`, `val`, and `test` sets for model training.

Make sure all dependencies are installed (primarily `opencv-python`, `mediapipe`, `numpy`, `pandas`, `matplotlib`, `scikit-learn`).
